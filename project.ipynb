{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"279b008bf2fc455badd3865aabf9179b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":660,"execution_start":1708470146690,"source_hash":null},"outputs":[],"source":["import os\n","from collections import Counter\n","from itertools import product\n","from tqdm import tqdm\n","import torch\n","import torch.nn as nn\n","import math\n","import random\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader\n","import matplotlib.pyplot as plt\n","from torcheval.metrics.text import Perplexity\n","import nltk\n","from sentence_transformers import SentenceTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device "]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"080bee1d76a943329a074e904541d51b","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1988,"execution_start":1708470147359,"source_hash":null},"outputs":[],"source":["\n","\n","folder_path = 'dat410_europarl/'\n","\n","translations = {}\n","file_list = os.listdir(folder_path)\n","text_files = [file for file in file_list]\n","for text_file in text_files:\n","    file_path = os.path.join(folder_path, text_file)\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        translations[file_path.split(\".\")[-1]] = [l[:-1] for l in file.readlines()]\n","        \n","translations[\"sv\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6408372987f14d9cb2e8974f2f772e81","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3016,"execution_start":1708470154468,"source_hash":null},"outputs":[],"source":["simpel_translator = torch.load(\"simpel_translator.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"6b98a66cd9bc47efba3ba356c3f4aada","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":821,"execution_start":1708470157489,"source_hash":null},"outputs":[],"source":["translator_dict = {}\n","for (swe_word, eng_word), prob in simpel_translator.items():\n","    eng_dict = translator_dict.get(eng_word, {})\n","    eng_dict[swe_word] = prob\n","    translator_dict[eng_word] = eng_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a59990c4491d4cd998a667549b51f351","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":75,"execution_start":1708470158324,"source_hash":null},"outputs":[],"source":["\n","def simpel_translate_setance(sentence, translator_dict):\n","    out = []\n","    for word in sentence.split(\" \"):\n","        out.append(max(translator_dict[word], key=lambda k: translator_dict[word][k]))\n","    return \" \".join(out)\n","sentence = \"mrs lynne , you are quite right and i shall check whether this has actually not been done .\"\n","\n","simpel_translate_setance(sentence, translator_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["swe_count = Counter(\" \".join(translations[\"sv\"]).split(\" \"))\n","eng_count = Counter(\" \".join(translations[\"en\"]).split(\" \"))\n","print(swe_count.most_common(20))\n","print(eng_count.most_common(20))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","model_name = 'bert-base-nli-mean-tokens'\n","bert_model = SentenceTransformer(model_name)\n","def split_into_chunks(lst, chunk_size):\n","    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bert_encodings = torch.tensor(bert_model.encode(translations[\"en\"]))\n","bert_encodings.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["swe_vocab = [t[0] for t in swe_count.most_common()]\n","swe_vocab = [\"<UKN>\", \"<PAD>\", \"<s>\", \"</s>\"] + swe_vocab[:int(len(swe_vocab) * 0.35)]\n","print(\"Portion of unknow swedish words in the corpus\", 1 -sum([swe_count[w] for w in swe_vocab]) / sum(swe_count.values()))\n","print(\"Length of vocab\",  len(swe_vocab))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["swe_id2word = {i:w for i, w in enumerate(swe_vocab)}\n","swe_word2id = {w:i for i, w in enumerate(swe_vocab)}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["swe_id2word[3572]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Transalte wprds in to ids, with start and end tokens at respective ends\n","swe_tokens = [[2] + [swe_word2id.get(w, 0) for w in scent.split(\" \")] + [3] for scent in  translations[\"sv\"]]\n","max_len = max([len(ids) for ids in swe_tokens])\n","#Add padding such that all scentances are of equal length\n","swe_tokens = [scent + [1] * (max_len - len(scent)) for scent in swe_tokens]\n","#Assert that they are of equal length\n","assert all([len(ids) == len(swe_tokens[0]) for ids in swe_tokens])\n","swe_tokens, len(swe_tokens), len(swe_tokens[0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def random_split_list(input_list, split_ratio):\n","    assert 0 <= split_ratio <= 1, \"Split ratio must be between 0 and 1\"\n","\n","    values = input_list.copy()\n","    random.shuffle(values)\n","\n","    split_index = int(len(values) * split_ratio)\n","    first_list = values[:split_index]\n","    second_list = values[split_index:]\n","\n","    return first_list, second_list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_indecies, rest = random_split_list(list(range((bert_encodings.shape[0]))), 0.7)\n","val_indecies, test_indecies= random_split_list(rest, 0.5)\n","assert len(train_indecies) + len(val_indecies) + len(test_indecies) == bert_encodings.shape[0]\n","assert sorted(train_indecies + val_indecies + test_indecies) == list(range(bert_encodings.shape[0]))\n","train_indecies[:10], val_indecies[:10], test_indecies[:10]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_eng = bert_encodings[train_indecies]\n","train_swe = torch.tensor(swe_tokens)[train_indecies]\n","\n","val_eng = bert_encodings[val_indecies]\n","val_swe = torch.tensor(swe_tokens)[val_indecies]\n","\n","test_eng = bert_encodings[test_indecies]\n","test_swe = torch.tensor(swe_tokens)[test_indecies]\n","\n","assert train_eng.shape[0] + val_eng.shape[0] + test_eng.shape[0] == bert_encodings.shape[0]\n","train_eng.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class TextEncoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, output_size, dropout_prob):\n","        super(TextEncoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_prob)\n","        self.linear = nn.Linear(hidden_dim * num_layers, output_size)\n","\n","    def forward(self, input_text):\n","        embedded_text = self.embedding(input_text)\n","        lstm_out, (hiddens, _) = self.lstm(embedded_text)\n","        concat_hiddens = hiddens.permute(1, 0, 2).flatten(start_dim=1)\n","        output = self.linear(concat_hiddens)  # Apply linear layer\n","        return output\n","    \n","class TextDecoder(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_size,num_layers, encoding_size, dropout):\n","        super(TextDecoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.encoding_size = encoding_size\n","        \n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim + encoding_size, hidden_size, num_layers,  dropout=dropout, batch_first=True)# Concatenated input size: hidden_size + encoding_size\n","        self.out = nn.Linear(hidden_size, vocab_size)\n","        self.softmax = nn.LogSoftmax(dim=2)  # Change softmax dimension to 2\n","\n","    def forward(self, encoding, input, hidden = None):\n","        #if hidden == None:\n","            #hidden = torch.zeros((input.shape[0], self.hidden_size))\n","        seq_len = input.size(1)\n","        \n","        # Repeat encoding along the sequence dimension\n","        repeated_encoding = encoding.unsqueeze(1).repeat(1, seq_len, 1)\n","        \n","        # Embed the input tokens\n","        embedded_input = self.embedding(input)\n","        \n","        # Concatenate embedding with encoding\n","        concatenated_input = torch.cat((embedded_input, repeated_encoding), dim=2)\n","        \n","        # Pass through RNN\n","        if hidden != None:\n","            output, hidden = self.rnn(concatenated_input, hidden)\n","        else:\n","            output, (hidden) = self.rnn(concatenated_input)\n","        \n","        # Compute output probabilities\n","        output = self.out(output)\n","        \n","        return output, hidden"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Seq2seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    \n","    def forward(self, input, target, teacher_forcing = True, start_token = None, max_length = None):\n","        context = self.encoder(input)\n","        return self.decoder(context, target, teacher_forcing, start_token, max_length)\n","    \n","class Encoder(nn.Module):\n","    def __init__(self, in_vocab_size,out_vocab_size, embedding_dim_in,embedding_dim_out,\n","                            hidden_dim, num_layers, dropout_rate):\n","        super(Encoder, self).__init__()\n","        self.out_vocab_size = out_vocab_size\n","        self.num_layers = num_layers\n","        self.in_embedding = nn.Embedding(in_vocab_size, embedding_dim_in)\n","        self.lstm = nn.LSTM(embedding_dim_in, hidden_dim, num_layers=num_layers, \n","                                       dropout=dropout_rate, batch_first=True)\n","\n","    def forward(self, context_sequence):\n","        # LSTM encoding for context_sequence\n","        embeded = self.in_embedding(context_sequence)\n","        _ , (hidden, cells) = self.lstm(embeded)\n","        return (hidden, cells)\n","class Decoder(nn.Module):\n","    def __init__(self,out_vocab_size,embedding_dim_out,\n","                 hidden_dim, num_layers, dropout_rate):\n","            super(Decoder, self).__init__()\n","            self.dropout = nn.Dropout(dropout_rate)\n","            self.out_embedding = nn.Embedding(out_vocab_size, embedding_dim_out)\n","            self.lstm = nn.LSTM(embedding_dim_out, hidden_dim, num_layers=num_layers,\n","                            dropout=dropout_rate, batch_first=True)\n","            self.fc = nn.Linear(hidden_dim, out_vocab_size)\n","\n","    def forward(self, hidden, x, teacher_forcing = True, start_token = None, max_length = None):\n","        \n","\n","\n","        # Embedding for input sequence\n","        embedding_x = self.dropout(self.out_embedding(x))\n","\n","        #layered_context = context.repeat(self.num_layers_de, 1, 1)\n","        \n","       \n","        \n","        \n","        if teacher_forcing:\n","            # LSTM processing\n","            output, hidden = self.lstm(embedding_x, hidden)\n","        else:\n","            assert start_token != None and max_length != None\n","            \n","            decoder_input = self.out_embedding(torch.tensor([[start_token]] * x.shape[0], device=device))\n","            decoder_outputs = None\n","            \n","          \n","            for t in range(max_length):\n","                decoder_output, hidden = self.lstm(decoder_input, hidden)\n","                if decoder_outputs == None:\n","                    decoder_outputs = decoder_output\n","                else:\n","                    decoder_outputs = torch.cat((decoder_outputs, decoder_output), dim = 1)\n","                \n","                # Use the predicted token as input for the next timestep\n","                probs =  self.fc(decoder_output.float())\n","                decoder_input = self.out_embedding(probs.argmax(dim=2))\n","            output = decoder_outputs\n","            \n","            \n","\n","        # Apply dropout\n","        output = self.dropout(output)\n","\n","        # Final prediction\n","        prediction = self.fc(output)\n","        return prediction\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Vec2hidden(nn.Module):\n","    def __init__(self, num_layers) -> None:\n","        super().__init__()\n","        self.num_layers = num_layers\n","    def forward(self, context):\n","        layered_context = context.repeat(self.num_layers, 1, 1)\n","        hidden = (layered_context.to(device), torch.zeros_like(layered_context).to(device))\n","        return hidden"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def moving_average(data, window_size):\n","    moving_averages = []\n","    for i in range(len(data)):\n","        start_index = max(0, i - window_size + 1)\n","        end_index = min(i + 1, len(data))\n","        window = data[start_index:end_index]\n","        average = sum(window) / len(window)\n","        moving_averages.append(average)\n","    return moving_averages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dec_order_any(values, n):\n","    if len(values) <= 1:\n","        return True\n","    lessers = [a> b for a,b in zip(values[:-1], values[1:])]\n","    if  n >= len(lessers):\n","        return any(lessers)\n","    return any(lessers[-n:])\n","dec_order_any([10], 2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","swe_vocab_size= len(swe_vocab)\n","hidden_size = 768\n","de_embed_size = 1024\n","depth = 5\n","drop_rate = 0.1\n","\n","\n","prob_threahold = 0\n","prob_step = 0\n","lr  = 0.0005\n","batch_size = 8\n","\n","num_epochs = 10\n","wd = 2e-6\n","\n","early_stop = 4\n","\n","c = 1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["force = False\n","model_name = \"bertEnc.pth\"\n","\n","decoder_args = (swe_vocab_size, de_embed_size, hidden_size, depth, drop_rate)\n","if not os.path.exists(model_name) or force:\n","    \n","    model = Seq2seq(Vec2hidden(depth), Decoder(swe_vocab_size, de_embed_size, hidden_size, depth, drop_rate).to(device))\n","    \n","    train_loader = DataLoader(TensorDataset(train_eng, train_swe), batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(TensorDataset(val_eng, val_swe), batch_size=batch_size, shuffle=True)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n","    loss_function = nn.CrossEntropyLoss()\n","    #progress = tqdm(total=num_epochs * (len(train_loader) / batch_size + len(val_loader) / batch_size + 2))\n","\n","    train_losses = []\n","    val_losses = []\n","    epochs_mean_val_losses = []\n","    try:\n","        for epoch in (range(num_epochs)):\n","            total_loss = 0\n","            num_batches = 0\n","            epoch_train_losses = []\n","            epoch_val_losses = []\n","            nr_batches = len(train_loader)\n","            for eng_encoding, swe_text in tqdm(train_loader):\n","                prob_threahold += prob_step / nr_batches\n","\n","                eng_encoding = eng_encoding.to(device)\n","                indecies = torch.where((swe_text == 1).sum(dim =0) == batch_size)[0]\n","                first_pad_swe = indecies[0].item() if indecies.shape[0] != 0 else swe_text.shape[1]\n","                swe_text = swe_text[:, :first_pad_swe].to(device)\n","                \n","\n","            \n","               \n","                if prob_threahold < random.random():\n","                    decoding = model.forward(eng_encoding, swe_text[:,:-1]) #teacherforcing\n","                else:\n","                    decoding = model.forward(eng_encoding, swe_text[:,:-1], \n","                                            False, swe_word2id[\"</s>\"], int(swe_text[:,1:].shape[1])) #autoregresive\n","                \n","                ground_truth = F.one_hot(swe_text[:,1:], swe_vocab_size).float()\n","                flat_preds = decoding.view(-1, decoding.size(-1))\n","                flat_target = ground_truth.view(-1, ground_truth.size(-1))\n","                loss = loss_function(flat_preds, flat_target) * batch_size / flat_preds.shape[0]\n","               \n","                \n","                optimizer.zero_grad()\n","            \n","                loss.backward()\n","                \n","                optimizer.step()\n","                epoch_train_losses.append(loss.item())\n","\n","\n","            for eng_encoding, swe_text in (val_loader):\n","                with torch.no_grad():\n","                    \n","                    eng_encoding = eng_encoding.to(device)\n","                    indecies = torch.where((swe_text == 1).sum(dim =0) == batch_size)[0]\n","                    first_pad_swe = indecies[0].item() if indecies.shape[0] != 0 else swe_text.shape[1]\n","                    swe_text = swe_text[:, :first_pad_swe].to(device)\n","                    \n","                    decoding = model.forward(eng_encoding, swe_text[:,:-1]) #teacherforcing\n","                  \n","                    ground_truth = F.one_hot(swe_text[:,1:], swe_vocab_size).float()\n","                    flat_preds = decoding.view(-1, decoding.size(-1))\n","                    flat_target = ground_truth.view(-1, ground_truth.size(-1))\n","                    loss = loss_function(flat_preds, flat_target) * batch_size / flat_preds.shape[0]\n","                    \n","                    epoch_val_losses.append(loss.item())\n","\n","            val_losses.extend(epoch_val_losses)\n","            train_losses.extend(epoch_train_losses)\n","\n","            print(\"train \",sum(epoch_train_losses) / len(epoch_train_losses), \"val\", sum(epoch_val_losses) / len(epoch_val_losses))\n","\n","            epochs_mean_val_losses.append(sum(epoch_val_losses) / len(epoch_val_losses))\n","            \"\"\"if not dec_order_any(epochs_mean_val_losses, early_stop):\n","                print(\"val went up\", early_stop, \"times\")\n","                break\"\"\"\n","    except KeyboardInterrupt:\n","        torch.save({\"model\": model.state_dict(), \n","                    \"decoder_args\": decoder_args,\n","                    \"train_losses\": train_losses,\n","                    \"val_losses\": val_losses,\n","                    \"lr\":lr, \n","                    \"batch_size\": batch_size, \n","                    \"num_epochs\":num_epochs, \n","                    \"wd\":wd },\n","                    model_name)\n","    torch.save({\"model\": model.state_dict(), \n","                        \"decoder_args\": decoder_args,\n","                        \"train_losses\": train_losses,\n","                        \"val_losses\": val_losses,\n","                        \"lr\":lr, \n","                        \"batch_size\": batch_size, \n","                        \"num_epochs\":num_epochs, \n","                        \"wd\":wd },\n","                        model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_dict = torch.load(model_name)\n","train_losses =model_dict[\"train_losses\"]\n","val_losses = model_dict[\"val_losses\"]\n","model = Seq2seq(Vec2hidden(depth),Decoder(*model_dict[\"decoder_args\"])).to(device)\n","model.load_state_dict(model_dict[\"model\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_dict[\"wd\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_eng.shape, test_swe.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"\"\"def calculate_perplexity(model, dataloader, device):\n","\n","    with torch.no_grad():\n","        metric=Perplexity().to(device)\n","        perplexities = []\n","        for inputs, targets in tqdm(dataloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            encodings = model.forward_context(inputs)\n","            preds = model.forward(encodings, targets)\n","            \n","            if preds.shape[0] == targets.shape[0]:\n","                metric.update(preds, targets)\n","                perplexity = metric.compute()\n","                perplexities.append(perplexity.item())\n","            else:\n","                print(\":(\")\n","\n","    return sum(perplexities) / len(perplexities)\n","\n","d = torch.load(\"perplexities.pth\")\n","if d.get(model_name[:-4], None) == None or force:\n","    p = calculate_perplexity(model, DataLoader(TensorDataset(test_eng, test_swe), batch_size=8), device)\n","    d[model_name[:-4]] = p\n","    torch.save(d, \"perplexities.pth\")\n","\n","d[model_name[:-4]], d\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","plt.plot((range(len(train_losses))), moving_average(train_losses, 200))\n","x = [int(a * len(train_losses) / len(val_losses)) for a in range(len(val_losses))]\n","plt.plot(x, moving_average(val_losses, 200))\n","plt.ylim(0.01, 0.1)\n","plt.xlim(200)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def select_from_topk(input_tensor, k):\n","    values, indecies = torch.topk(input_tensor, k, dim=1)\n","    sub_indecy = torch.multinomial(values[0], 1, replacement=True)[0].item()\n","    return indecies[0,sub_indecy]\n","\n","def translate(model ,input_encoding, out_vocab,out_start_token, out_end_token, k = 5, max = 20):\n","    model.eval()\n","    with torch.no_grad():\n","        translation = torch.tensor([out_start_token]).to(device)\n","        hidden = None\n","        for _ in range(max):\n","            output = model.forward(input_encoding, translation.unsqueeze(0))\n","            logits = output[0,-1]\n","            logits[0] = float('-inf')\n","            logits[2] = float('-inf')\n","            next_token_prob = torch.softmax(logits, dim = 0)\n","            a = select_from_topk(next_token_prob.unsqueeze(0), k).to(device)\n","            translation = torch.concat((translation, a.unsqueeze(0)))\n","            if a == out_end_token:\n","                break\n","        return \" \".join([out_vocab[int(t.item())] for t in translation])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["encoding = torch.tensor(bert_model.encode(\"you have not.\")).unsqueeze(0)\n","translate(model,encoding , swe_id2word, \n","          swe_word2id[\"<s>\"], swe_word2id[\"</s>\"],\n","          k = 10, max=30)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import evaluation\n","\n","references = [translations[\"sv\"][i] for i in test_indecies]\n","input_data = [translations[\"en\"][i] for i in test_indecies]\n","\n","evaluation.write_references_to_file(references, \"reference.txt\")\n","evaluation.write_references_to_file(input_data, \"input_data.txt\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["translation_func = lambda x: translate(model, torch.tensor(bert_model.encode(x)).unsqueeze(0) , swe_id2word, \n","                    swe_word2id[\"<s>\"], swe_word2id[\"</s>\"],\n","                    k = 3, max=30)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluation.write_translatons_to_file(\"input_data.txt\", \"predictions.txt\", translation_func)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from evaluation import evaluate_model\n","\n","test = evaluate_model(\"reference.txt\", \"predictions.txt\")\n","\n","print(test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.bar([\"ibm\", \"lstm\"], [0.3, 0.13])\n"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"0d4262044ad94325a7187eae975cb35d","kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
